# Cogniwear-image-sound-detection
A smart wearable device integrating IoT and AI for enhanced human-machine interaction. Using a Raspberry Pi camera and microphone, it provides speech and image recognition, especially aiding visually impaired users. A built-in button allows mode switching, improving accessibility and usability in daily tasks.

#final.py:                    
Purpose: Performs image detection using Google API key. It captures an image, displays it, and prompts the user to ask a question about the picture. The program then converts the user's spoken question to text and provides an audio response about the picture.
Functionality:
Captures and displays an image.
Prompts the user to ask a question about the picture.
Converts spoken question to text input.
Provides an audio response based on the question asked.


#test.py:
Purpose: Generates an audio output based on predefined input in the code. Upon running the file, it directly outputs the predefined answer through audio.
Functionality:
Provides predefined input.
Outputs the answer as audio.


#vid.py:
Purpose: Runs a video for a specified duration (e.g., 20 seconds) and continuously describes the contents of the video.
Functionality:
Plays a video for a specified duration.
Provides continuous audio description of the video content.

#Summary:
These Python files serve different purposes within the project, including image detection, audio output based on input, and video description. Each file contributes to the overall functionality of the CogniWear device, enhancing its capabilities in image and sound recognition.
